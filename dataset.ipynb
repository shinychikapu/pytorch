{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from torchvision.io import read_image\n",
    "import os\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Custom Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class catDogDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, rootFolder):\n",
    "        self.rootFolder = rootFolder\n",
    "        self.paths = []\n",
    "        self.labels = []\n",
    "        self.getImgsAndLabels()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self,  index):\n",
    "        image = self.paths[index]\n",
    "        return self.reformat(image), self.labels[index]\n",
    "\n",
    "    def reformat(self, img_path):\n",
    "        '''This function take in a image path and return it as a (1, 28, 28) tensor to pass into the NN Model\n",
    "        \n",
    "        Attribute:\n",
    "        ---------\n",
    "        img_path : the path to the image on the computer\n",
    "        '''\n",
    "        img = np.asarray(Image.open(img_path)) \n",
    "\n",
    "        #resize to 28x28\n",
    "        img = cv.resize(img, (148, 148)) \n",
    "\n",
    "        if (img.shape != (148, 148)):\n",
    "            #convert to gray scale\n",
    "            img = cv.cvtColor(img, cv.COLOR_BGR2GRAY) #note that color is still from 0 to 255\n",
    "\n",
    "\n",
    "        #Making the color to be between 0 and 255\n",
    "        img = np.float32(img / 255)\n",
    "\n",
    "        #reshape and convert to tensor\n",
    "        img_ = torch.from_numpy(img).reshape(1, 148, 148)\n",
    "        return img_\n",
    "\n",
    "    \n",
    "    def getImgsAndLabels(self):\n",
    "        #get the list of class folders\n",
    "        # os.listdir(self.rootFolder) lists all the items (files and folders) in the self.rootFolder directory.\n",
    "        #os.path.isdir(os.path.join(self.rootFolder, folder_name) return a boolean value to indicate if the path is a directory\n",
    "        class_folders = [folder_name for folder_name in os.listdir(self.rootFolder) if os.path.isdir(os.path.join(self.rootFolder, folder_name))]\n",
    "\n",
    "        #mapping the img path with their labels\n",
    "        for class_folder in class_folders:\n",
    "            #Extracting the class labels and img file names\n",
    "            if (class_folder == \"Cat\"):\n",
    "                class_label = 1\n",
    "            else:\n",
    "                class_label = 0\n",
    "\n",
    "            class_folder_path = os.path.join(self.rootFolder, class_folder) #join automatically assign the correct separator between the folders names\n",
    "            #if file name ends with 'jpg' then add to list\n",
    "            img_names = [img_name for img_name in os.listdir(class_folder_path) if img_name.endswith('.jpg')]\n",
    "            \n",
    "            #Getting the complete path directories for  the images and append it to the self.image_paths list\n",
    "            self.paths.extend([os.path.join(class_folder_path, img_name) for img_name in img_names])\n",
    "            #Getting the labels\n",
    "            self.labels.extend([class_label] * len(img_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('data')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "temp = Path('data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte')\n",
    "temp.parent"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Splitting train/test/val sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import splitfolders\n",
    "\n",
    "splitfolders.ratio(input = \"PetImages\", output= \"Output\", seed = 873, ratio = (0.8, 0.1, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = catDogDataset(\"Output/train\")\n",
    "test_set = catDogDataset(\"Output/test\")\n",
    "val_set = catDogDataset(\"Output/val\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([70, 1, 148, 148])\n",
      "Shape of y: torch.Size([70]) torch.int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "206"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataLoader = DataLoader(dataset = train_set,\n",
    "                        batch_size = 70, \n",
    "                        shuffle= True,\n",
    "                        drop_last= True)\n",
    "for picture, label in train_dataLoader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {picture.shape}\")\n",
    "    print(f\"Shape of y: {label.shape} {label.dtype}\")\n",
    "    break\n",
    "len(train_dataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataLoader = DataLoader(dataset = test_set,\n",
    "                             batch_size = 70,\n",
    "                             shuffle= True,\n",
    "                             drop_last= True)\n",
    "val_dataLoader = DataLoader(dataset = val_set,\n",
    "                            batch_size = 70,\n",
    "                            shuffle= True,\n",
    "                            drop_last= True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating the Neural Network Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CatDogModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(148*148, 300), #input to first layer\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(300, 200), #first to second layer\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(200, 100), #second to third layer\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 2) #third layer to output cat or dog\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "    \n",
    "model = CatDogModel().to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Writing the train function**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fun = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the train function. The train function should take in the dataloader, model, the loss fuction, and the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fun, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    for batch, (pic, lab) in enumerate(dataloader):\n",
    "        pic, lab = pic.to(device), lab.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(pic)\n",
    "        loss = loss_fun(pred, lab)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward() #compute the loss function's gradients\n",
    "        optimizer.step() #update the parameters\n",
    "        optimizer.zero_grad() #clear the model's gradient to avoid gradient accumulation\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the test function. The test function only take the dataloader, model and the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_validate(dataloader, model, loss_fun):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for pic, lab in dataloader:\n",
    "            pic, lab = pic.to(device), lab.to(device)\n",
    "            pred = model(pic)\n",
    "            test_loss += loss_fun(pred, lab).item() #get the loss\n",
    "            correct += (pred.argmax(1) == lab).type(torch.float).sum().item() #get how many times the model guess correctuly\n",
    "    test_loss /= num_batches #loss per batch\n",
    "    correct /= size #accuracy\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\pytorch\\venv\\lib\\site-packages\\PIL\\TiffImagePlugin.py:864: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 66.9%, Avg loss: 0.619659 \n",
      "\n",
      "epoch: 2\n",
      "Test Error: \n",
      " Accuracy: 66.9%, Avg loss: 0.618858 \n",
      "\n",
      "epoch: 3\n",
      "Test Error: \n",
      " Accuracy: 66.8%, Avg loss: 0.619093 \n",
      "\n",
      "epoch: 4\n",
      "Test Error: \n",
      " Accuracy: 66.5%, Avg loss: 0.620293 \n",
      "\n",
      "epoch: 5\n",
      "Test Error: \n",
      " Accuracy: 66.6%, Avg loss: 0.619431 \n",
      "\n",
      "done lol\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "\n",
    "for i in range(epochs):\n",
    "    print(\"epoch:\", i + 1)\n",
    "    train(train_dataLoader, model, loss_fun, optimizer)\n",
    "    test_validate(val_dataLoader, model, loss_fun)\n",
    "print(\"done lol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m eee \u001b[39m=\u001b[39m cv\u001b[39m.\u001b[39mimread(image_path)\n\u001b[0;32m      6\u001b[0m \u001b[39m#cv.imshow(\"img\", eee)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39m#cv.waitKey(0)\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m eee\u001b[39m.\u001b[39;49mshape\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "image_path = r\"Output\\train\\Cat\\7968.jpg\"\n",
    "print(os.path.exists(image_path))\n",
    "\n",
    "eee = cv.imread(image_path)\n",
    "\n",
    "#cv.imshow(\"img\", eee)\n",
    "#cv.waitKey(0)\n",
    "eee.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
